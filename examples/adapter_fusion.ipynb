{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYZH02h-JeX5"
      },
      "source": [
        "# **AdapterFusion for Sequence Classification**\n",
        "\n",
        "In this example we will be fine-tuning the model *BERT-base-uncased* to classify a sequence of tokens. For this purpose, we will use a PEFT method called **Adapter Fusion**, which creates a mixture of mutiple pretrained adapters. We will use **transformers** to download tokenizers, **datasets** for data downdload **adapters** for creating adapters models and training, **evaluate** for loading evaluation metrics and **wandb** (Weights & Biases) to log the results.\n",
        "\n",
        "You can also open this example in google colab:\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wicwik/peft_tutorial/blob/main/examples/adapter_fusion.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **0. Install and import required modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7jMXwq62JQ7I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# 4.36.0 for compatibility with adapters\n",
        "%pip install -q --user transformers==4.36.0\n",
        "%pip install -q --user datasets\n",
        "%pip install -q --user adapters\n",
        "%pip install -q --user evaluate\n",
        "%pip install -q --user wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import evaluate\n",
        "import wandb\n",
        "import logging\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertConfig,\n",
        "    TrainingArguments,\n",
        "    default_data_collator\n",
        ")\n",
        "\n",
        "from adapters import BertAdapterModel, AdapterTrainer\n",
        "from adapters.composition import Fuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1. Set variables**\n",
        "\n",
        "We will be fine-tuning the pre-trained version of model [bert-base-uncased](https://huggingface.co/google-bert/bert-large-uncased) which has **110M** parameters. We will set the max **input length to 128** tokens and train for **3 epochs** with **batch size of 32**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "model_name_or_path = \"bert-base-uncased\"\n",
        "tokenizer_name_or_path = \"bert-base-uncased\"\n",
        "\n",
        "max_length = 128\n",
        "lr = 1e-3\n",
        "num_epochs = 3\n",
        "batch_size = 32 # in case of \"unable to allocate\" errors, decrease batch size to some lower number (e.g. 8 or 16)\n",
        "\n",
        "logging.disable(logging.WARNING)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2. Dataset and preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset that we will be using is called [Commitment Bank](https://huggingface.co/datasets/super_glue/viewer/cb) (CB) from SuperGLUE benchmark. This dataset contains a set of premise-hypothesis pairs where the premise is a passage and the hypothesis is a clause. If the clause is contained within the passage and it is an entailment then the target is 0, for a contradiction it is 1, and 2 for a neutral clause.\n",
        "\n",
        "The dataset contains **250 training samples and 56 validation samples**. We will also split the validation part of the dataset in half to create a test part for evaluation after training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'premise': 'It was a complex language. Not written down but handed down. One might say it was peeled down.',\n",
              " 'hypothesis': 'the language was peeled down',\n",
              " 'idx': 0,\n",
              " 'label': 0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"super_glue\", \"cb\")\n",
        "\n",
        "# test set is not labeled so we need to do custom splits\n",
        "validtest = dataset[\"validation\"].train_test_split(test_size=0.5)\n",
        "\n",
        "dataset[\"validation\"] = validtest[\"train\"]\n",
        "dataset[\"test\"] = validtest[\"test\"]\n",
        "\n",
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will tokenize the dataset. We only don't need to tokenize the labels this time, because we will train a classification head that returns numbers and not strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec0ebd3c43f4466fa75839720672104e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abdc4cfaf7484257ae6e25ba548a85a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "288b25cc224f42a992b58d22a9f64dba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "344aeba3f8e744c48bd06f7ea75aa6df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/28 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9a121a5b0104897a35a14027dbebea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/28 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(tokenizer_name_or_path)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "dataset = dataset.map(preprocess_function, batched=True)\n",
        "processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=[\"premise\", \"hypothesis\", \"idx\"],\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "processed_datasets = processed_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "train_dataset = processed_datasets[\"train\"].shuffle()\n",
        "eval_dataset = processed_datasets[\"validation\"]\n",
        "test_dataset = processed_datasets[\"test\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3. Create Adapters model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will create the Adapters model and adapter fusion. At frist we load *BertAdapterModel* using the Adapters module, and after that we will load **3 pre-trained adapters** to the model. These adapters are pretrained on **MNLI** (cross genre NLI), **QQP** (question paraphrase) and **QNLI** (QA NLI). As we don't need their prediction heads, we pass **with_head=False** to the loading method.\n",
        "\n",
        "After that we will add an adapter fusion layer, that combines all 3 adapter layers, activate it and set it trainable. The *train_adapter_fusion()* does two things: It freezes all weights of the model (including adapters!) except for the fusion layer and classification head. It also activates the given adapter setup to be used in very forward pass.\n",
        "\n",
        "Here is how AdapterFusion layer looks like in the model:\n",
        "<p align=\"center\">\n",
        "<img src=\"../img/af.png\" alt=\"adapter_fusion_arch\" width=\"auto\" height=\"350\">\n",
        "<img src=\"../img/af_arch.png\" alt=\"adapter_fusion\" width=\"auto\" height=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Name                     Architecture         #Param      %Param  Active   Train\n",
            "--------------------------------------------------------------------------------\n",
            "multinli                 bottleneck          894,528       0.684       1       0\n",
            "qqp                      bottleneck          894,528       0.684       1       0\n",
            "qnli                     bottleneck          894,528       0.684       1       0\n",
            "--------------------------------------------------------------------------------\n",
            "Full model                               130,734,336     100.000               0\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertAdapterModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionWithAdapters(\n",
              "              (query): LoRALinear(\n",
              "                in_features=768, out_features=768, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (key): LoRALinear(\n",
              "                in_features=768, out_features=768, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (value): LoRALinear(\n",
              "                in_features=768, out_features=768, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (prefix_tuning): PrefixTuningLayer(\n",
              "                (prefix_gates): ModuleDict()\n",
              "                (pool): PrefixTuningPool(\n",
              "                  (prefix_tunings): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (output): BertSelfOutputWithAdapters(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): LoRALinear(\n",
              "              in_features=768, out_features=3072, bias=True\n",
              "              (loras): ModuleDict()\n",
              "            )\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutputWithAdapters(\n",
              "            (dense): LoRALinear(\n",
              "              in_features=3072, out_features=768, bias=True\n",
              "              (loras): ModuleDict()\n",
              "            )\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (adapters): ModuleDict(\n",
              "              (multinli): Adapter(\n",
              "                (non_linearity): Activation_Function_Class(\n",
              "                  (f): ReLU()\n",
              "                )\n",
              "                (adapter_down): Sequential(\n",
              "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
              "                  (1): Activation_Function_Class(\n",
              "                    (f): ReLU()\n",
              "                  )\n",
              "                )\n",
              "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
              "              )\n",
              "              (qqp): Adapter(\n",
              "                (non_linearity): Activation_Function_Class(\n",
              "                  (f): ReLU()\n",
              "                )\n",
              "                (adapter_down): Sequential(\n",
              "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
              "                  (1): Activation_Function_Class(\n",
              "                    (f): ReLU()\n",
              "                  )\n",
              "                )\n",
              "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
              "              )\n",
              "              (qnli): Adapter(\n",
              "                (non_linearity): Activation_Function_Class(\n",
              "                  (f): ReLU()\n",
              "                )\n",
              "                (adapter_down): Sequential(\n",
              "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
              "                  (1): Activation_Function_Class(\n",
              "                    (f): ReLU()\n",
              "                  )\n",
              "                )\n",
              "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
              "              )\n",
              "            )\n",
              "            (adapter_fusion_layer): ModuleDict(\n",
              "              (multinli,qqp,qnli): BertFusion(\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "    (invertible_adapters): ModuleDict()\n",
              "    (shared_parameters): ModuleDict()\n",
              "    (prefix_tuning): PrefixTuningPool(\n",
              "      (prefix_tunings): ModuleDict()\n",
              "    )\n",
              "    (prompt_tuning): PromptTuningLayer(\n",
              "      (base_model_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (prompt_tunings): ModuleDict()\n",
              "    )\n",
              "  )\n",
              "  (heads): ModuleDict(\n",
              "    (default): BertStyleMaskedLMHead(\n",
              "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (1): Activation_Function_Class(\n",
              "        (f): GELUActivation()\n",
              "      )\n",
              "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (3): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "    (cb): ClassificationHead(\n",
              "      (0): Dropout(p=0.1, inplace=False)\n",
              "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (2): Activation_Function_Class(\n",
              "        (f): Tanh()\n",
              "      )\n",
              "      (3): Dropout(p=0.1, inplace=False)\n",
              "      (4): Linear(in_features=768, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id2label = {id: label for (id, label) in enumerate(processed_datasets[\"train\"].features[\"labels\"].names)}\n",
        "\n",
        "config = BertConfig.from_pretrained(model_name_or_path, id2label=id2label)\n",
        "model = BertAdapterModel.from_pretrained(model_name_or_path, config=config)\n",
        "\n",
        "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
        "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
        "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
        "\n",
        "model.add_adapter_fusion(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
        "model.set_active_adapters(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
        "\n",
        "model.add_classification_head(\"cb\", num_labels=len(id2label))\n",
        "\n",
        "adapter_setup = Fuse(\"multinli\", \"qqp\", \"qnli\")\n",
        "model.train_adapter_fusion(adapter_setup)\n",
        "\n",
        "print(model.adapter_summary())\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We don't have a function to gen number of trainable parameters as in Hugging Face PEFT module, but we can use [their implemetation](https://github.com/huggingface/peft/blob/main/src/peft/peft_model.py#L492) also for this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 22,467,645 || all params: 134,633,469 || trainable%: 16.688008685269782\n"
          ]
        }
      ],
      "source": [
        "trainable_params = 0\n",
        "all_param = 0\n",
        "for n, param in model.named_parameters():\n",
        "    num_params = param.numel()\n",
        "    if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
        "        num_params = param.ds_numel\n",
        "\n",
        "    if param.__class__.__name__ == \"Params4bit\":\n",
        "        num_params = num_params * 2\n",
        "\n",
        "    all_param += num_params\n",
        "    if param.requires_grad:\n",
        "        # print(n)\n",
        "        trainable_params += num_params\n",
        "\n",
        "\n",
        "print(f\"trainable params: {trainable_params:,d} || all params: {all_param:,d} || trainable%: {100 * trainable_params / all_param}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **4. Training and evaluation**\n",
        "\n",
        "We will be using Hugging Face [TrainingArguments](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/trainer#transformers.TrainingArguments) and [AdapterTrainer](https://docs.adapterhub.ml/training.html#adaptertrainer) from Adapter Hub (this adapter is based on transformers adapter). The BERT model is not generating tokens, therefore we don't need to do any postprocessing and can use the metric form *evaluate.load()*. The trainer will take a *compute_metrics* method that will be used to compute metrics during the evaluation. \n",
        "\n",
        "For SuperGLUE CB dataset *evaluate* computes F1 and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"super_glue\", \"cb\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    preds = preds.argmax(axis=1)\n",
        "\n",
        "    return metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"out\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    learning_rate=lr,\n",
        "    num_train_epochs=num_epochs,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will do the training and evaluation, similar to the [LoRA notebook](https://github.com/Wicwik/peft_tutorial/blob/main/examples/lora_seq2seq.ipynb). We can again have a look at the memory usage.\n",
        "\n",
        "Since *AdapterTrainer* class is inherited from the Transformers *Trainer* class, we can see the trainer uploading results to the *wandb*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "wandb version 0.16.4 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/jovyan/peft_tutorial/examples/wandb/run-20240315_095454-u726rpb6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rbelanec/huggingface/runs/u726rpb6' target=\"_blank\">earthy-gorge-86</a></strong> to <a href='https://wandb.ai/rbelanec/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rbelanec/huggingface' target=\"_blank\">https://wandb.ai/rbelanec/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rbelanec/huggingface/runs/u726rpb6' target=\"_blank\">https://wandb.ai/rbelanec/huggingface/runs/u726rpb6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 00:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.995700</td>\n",
              "      <td>0.804874</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.518315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.565400</td>\n",
              "      <td>0.662531</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.569195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.362300</td>\n",
              "      <td>0.696662</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.569425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cbf286117534914987bff77ba6822a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.040 MB of 0.106 MB uploaded\\r'), FloatProgress(value=0.3746522494620558, max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁██</td></tr><tr><td>eval/f1</td><td>▁██</td></tr><tr><td>eval/loss</td><td>█▁▃</td></tr><tr><td>eval/runtime</td><td>█▁▄</td></tr><tr><td>eval/samples_per_second</td><td>▁█▅</td></tr><tr><td>eval/steps_per_second</td><td>▁█▅</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▅▅████</td></tr><tr><td>train/global_step</td><td>▁▁▅▅████</td></tr><tr><td>train/learning_rate</td><td>█▅▁</td></tr><tr><td>train/loss</td><td>█▃▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.82143</td></tr><tr><td>eval/f1</td><td>0.56942</td></tr><tr><td>eval/loss</td><td>0.69666</td></tr><tr><td>eval/runtime</td><td>0.1194</td></tr><tr><td>eval/samples_per_second</td><td>234.483</td></tr><tr><td>eval/steps_per_second</td><td>33.498</td></tr><tr><td>test/accuracy</td><td>0.75</td></tr><tr><td>test/f1</td><td>0.52199</td></tr><tr><td>test/loss</td><td>1.12445</td></tr><tr><td>test/runtime</td><td>0.1157</td></tr><tr><td>test/samples_per_second</td><td>241.943</td></tr><tr><td>test/steps_per_second</td><td>34.563</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>24</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3623</td></tr><tr><td>train/total_flos</td><td>63819544896000.0</td></tr><tr><td>train/train_loss</td><td>0.64111</td></tr><tr><td>train/train_runtime</td><td>7.5282</td></tr><tr><td>train/train_samples_per_second</td><td>99.625</td></tr><tr><td>train/train_steps_per_second</td><td>3.188</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">earthy-gorge-86</strong> at: <a href='https://wandb.ai/rbelanec/huggingface/runs/u726rpb6' target=\"_blank\">https://wandb.ai/rbelanec/huggingface/runs/u726rpb6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240315_095454-u726rpb6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "\n",
        "if wandb.run is not None:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **5. Save and load**\n",
        "\n",
        "Now we can save the model with *save_adapter_fusion* and *save_all_adapters* methods to save the AdapterFusion layer and all trained adapters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "adapter_model_id = f\"{model_name_or_path}_adapterfusion_seqcls\"\n",
        "\n",
        "model.save_pretrained(adapter_model_id)\n",
        "model.save_adapter_fusion(adapter_model_id, \"multinli,qqp,qnli\")\n",
        "model.save_all_adapters(adapter_model_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can load the model and give it a custom example. It is important to **set active adapters** and to **speicfy the head** that we want to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fuse[multinli, qqp, qnli]\n",
            "{'input_ids': tensor([[  101,  1037, 12063,  1012,  2005,  2870,  1010,  1037,  2307, 12063,\n",
            "          1012,  2021,  2053,  2028,  2064,  2360,  3387, 15451,  8566,  2378,\n",
            "          2038,  2025,  2363, 15250,  1012,   102,  3387, 15451,  8566,  2378,\n",
            "          2038,  2025,  2363, 15250,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "entailment 0\n"
          ]
        }
      ],
      "source": [
        "model = BertAdapterModel.from_pretrained(adapter_model_id)\n",
        "model.set_active_adapters(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
        "\n",
        "print(model.active_adapters)\n",
        "\n",
        "inputs = tokenizer(\"A pity. For myself, a great pity. But no one can say Bishop Malduin has not received latitude.\", \n",
        "                   \"Bishop Malduin has not received latitude\", \n",
        "                   return_tensors=\"pt\"\n",
        "                   )\n",
        "print(inputs)\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs, head=\"cb\")[0]\n",
        "    class_id = torch.argmax(logits).item()\n",
        "    pred_class = id2label[class_id]\n",
        "    print(pred_class, class_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
