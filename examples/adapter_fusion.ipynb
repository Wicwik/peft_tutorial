{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYZH02h-JeX5"
      },
      "source": [
        "# Using adapters for Slovak boolq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7jMXwq62JQ7I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q --user transformers==4.35.2\n",
        "%pip install -q --user datasets\n",
        "%pip install -q --user adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, XmodConfig\n",
        "\n",
        "from adapters import XmodAdapterModel, AdapterConfig, Stack\n",
        "from adapters.composition import Fuse\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'passage', 'answer'],\n",
              "        num_rows: 4735\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['question', 'passage', 'answer'],\n",
              "        num_rows: 1700\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"crabz/boolq_sk\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': Value(dtype='string', id=None),\n",
              " 'passage': Value(dtype='string', id=None),\n",
              " 'answer': Value(dtype='bool', id=None)}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "adapter_model_name_or_path = \"AdapterHub/xmod-base\"\n",
        "model_name_or_path = \"facebook/xmod-base\"\n",
        "tokenizer_name_or_path = \"facebook/xmod-base\"\n",
        "\n",
        "label_column = \"answer\"\n",
        "max_length = 128\n",
        "lr = 1e-3\n",
        "num_epochs = 3\n",
        "batch_size = 32\n",
        "id2label = {0: \"no\", 1: \"yes\"}\n",
        "label2id = {\"no\": 0, \"yes\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbb93935ac4248dcbd8daa51e5ec3591",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4735 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c744308189d24a29a59486a7a9c254b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1700 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 4735\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 1700\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = []\n",
        "\n",
        "    keys = list(examples.keys())[:-1]\n",
        "    values = list(zip(*[examples[key] for key in keys]))\n",
        "\n",
        "\n",
        "    for value_set in values:\n",
        "        inputs.append(\", \".join(f\"{key}: {value}\" for key, value in zip(keys, value_set)))\n",
        "\n",
        "    \n",
        "    targets = examples[label_column]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    labels = [1 if tl else 0 for tl in targets]\n",
        "    model_inputs[\"labels\"] = labels\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "# Encode the input data\n",
        "dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"question\", \"passage\", \"answer\"])\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'labels': Value(dtype='int64', id=None)}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XmodAdapterModel were not initialized from the model checkpoint at AdapterHub/xmod-base and are newly initialized: ['heads.default.2.weight', 'heads.default.0.bias', 'heads.default.2.bias', 'heads.default.3.bias', 'heads.default.0.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "472d9af4250d4a8984f1ad7f1a13ce5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Active adapters: Stack[sk, boolq]\n"
          ]
        }
      ],
      "source": [
        "config = XmodConfig.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    id2label=id2label,\n",
        ")\n",
        "model = XmodAdapterModel.from_pretrained(\n",
        "    adapter_model_name_or_path,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "# Load the pre-trained adapters we want to fuse\n",
        "lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
        "model.load_adapter(\"AdapterHub/xmod-base-sk_SK\", load_as=\"sk\", source=\"hf\", config=lang_adapter_config)\n",
        "model.add_adapter(\"boolq\", set_active=True, config=AdapterConfig.load(\"pfeiffer\"))\n",
        "model.train_adapter([\"boolq\"])\n",
        "model.active_adapters = Stack(\"sk\", \"boolq\")\n",
        "model.add_classification_head(\"boolq\", num_labels=len(label2id), id2label=id2label, use_pooler=True)\n",
        "\n",
        "print(\"Active adapters:\", model.active_adapters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = torch.nn.BCEWithLogitsLoss()\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [{\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \\\n",
        "                                 \"weight_decay\": 1e-4,}, \\\n",
        "                                {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \\\n",
        "                                 \"weight_decay\": 0.0,},]\n",
        "optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters, lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import TrainingArguments, EvalPrediction\n",
        "from adapters import AdapterTrainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "def compute_accuracy(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return {\"acc\": (preds == p.label_ids).mean()}\n",
        "\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    compute_metrics=compute_accuracy,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='740' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [740/740 01:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.667700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.668300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.664000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=740, training_loss=0.6659518061457453, metrics={'train_runtime': 94.8229, 'train_samples_per_second': 249.676, 'train_steps_per_second': 7.804, 'total_flos': 1728547893580800.0, 'train_loss': 0.6659518061457453, 'epoch': 5.0})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6649482250213623,\n",
              " 'eval_acc': 0.6123529411764705,\n",
              " 'eval_runtime': 3.375,\n",
              " 'eval_samples_per_second': 503.701,\n",
              " 'eval_steps_per_second': 16.0,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
