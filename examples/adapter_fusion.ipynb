{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYZH02h-JeX5"
      },
      "source": [
        "# AdapterFusion for Sequence Classification\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wicwik/peft_tutorial/blob/main/examples/adapter_fusion.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jMXwq62JQ7I"
      },
      "outputs": [],
      "source": [
        "%pip install -q --user transformers==4.35.2\n",
        "%pip install -q --user datasets\n",
        "%pip install -q --user adapters\n",
        "%pip install -q --user wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import evaluate\n",
        "import wandb\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertConfig, TrainingArguments, default_data_collator\n",
        "\n",
        "from adapters import BertAdapterModel, AdapterTrainer\n",
        "from adapters.composition import Fuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "model_name_or_path = \"bert-base-uncased\"\n",
        "tokenizer_name_or_path = \"bert-base-uncased\"\n",
        "\n",
        "max_length = 180\n",
        "lr = 1e-3\n",
        "num_epochs = 3\n",
        "batch_size = 32 # in case of \"unable to allocate\" errors, decrease batch size to some lower number (e.g. 8 or 16) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"super_glue\", \"cb\")\n",
        "\n",
        "# test set is not labeled so we need to do custom splits\n",
        "validtest = dataset[\"validation\"].train_test_split(test_size=0.5)\n",
        "\n",
        "dataset[\"validation\"] = validtest[\"train\"]\n",
        "dataset[\"test\"] = validtest[\"test\"]\n",
        "\n",
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "dataset = dataset.map(preprocess_function, batched=True)\n",
        "processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=[\"premise\", \"hypothesis\", \"idx\"],\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "processed_datasets = processed_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "train_dataset = processed_datasets[\"train\"].shuffle()\n",
        "eval_dataset = processed_datasets[\"validation\"]\n",
        "test_dataset = processed_datasets[\"test\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id2label = {id: label for (id, label) in enumerate(processed_datasets[\"train\"].features[\"labels\"].names)}\n",
        "\n",
        "config = BertConfig.from_pretrained(model_name_or_path, id2label=id2label)\n",
        "model = BertAdapterModel.from_pretrained(model_name_or_path, config=config)\n",
        "\n",
        "\n",
        "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
        "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
        "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
        "\n",
        "model.add_adapter_fusion(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
        "model.set_active_adapters(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
        "\n",
        "model.add_classification_head(\"cb\", num_labels=len(id2label))\n",
        "\n",
        "adapter_setup = Fuse(\"multinli\", \"qqp\", \"qnli\")\n",
        "model.train_adapter_fusion(adapter_setup)\n",
        "\n",
        "print(model.adapter_summary())\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"super_glue\", \"cb\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    preds = preds.argmax(axis=1)\n",
        "\n",
        "    return metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"out\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    learning_rate=lr,\n",
        "    num_train_epochs=num_epochs,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")\n",
        "\n",
        "if wandb.run is not None:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "peft_model_id = f\"{model_name_or_path}_adapterfusion_seqcls\"\n",
        "\n",
        "model.save_adapter_fusion(peft_model_id, \"multinli,qqp,qnli\")\n",
        "model.save_all_adapters(peft_model_id)\n",
        "\n",
        "ckpt = f\"{peft_model_id}/model.safetensors\"\n",
        "!du -h $ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BertAdapterModel.from_pretrained(peft_model_id)\n",
        "model.set_active_adapters(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
        "\n",
        "print(model.active_adapters)\n",
        "\n",
        "inputs = tokenizer(\"A pity. For myself, a great pity. But no one can say Bishop Malduin has not received latitude.\", \n",
        "                   \"Bishop Malduin has not received latitude\", \n",
        "                   return_tensors=\"pt\"\n",
        "                   )\n",
        "print(inputs)\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs, head=\"cb\")[0]\n",
        "    pred_class = id2label[torch.argmax(logits).item()]\n",
        "    print(pred_class)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
